# Bug Fixing Guide for SqlScriptDOM

This guide provides a summary of the typical workflow for fixing a bug in the SqlScriptDOM parser, based on practical experience. For a more comprehensive overview of the project structure and code generation, please refer to the main [Copilot / AI instructions for SqlScriptDOM](copilot-instructions.md).

## Summary of the Bug-Fixing Workflow

The process of fixing a bug, especially one that involves adding new syntax, follows these general steps:

1.  **Grammar Modification**:
    *   Identify the correct grammar rule to modify in the `SqlScriptDom/Parser/TSql/*.g` files.
    *   Apply the necessary changes to all relevant `.g` files, from the version where the syntax was introduced up to the latest version (e.g., `TSql130.g` through `TSql170.g` and `TSqlFabricDW.g`).

2.  **Abstract Syntax Tree (AST) Update**:
    *   If the new syntax requires a new AST node or enum member, edit `SqlScriptDom/Parser/TSql/Ast.xml`. For example, adding a new operator like `NOT LIKE` required adding a `NotLike` member to the `BooleanComparisonType` enum.

3.  **Script Generation Update**:
    *   Update the script generator to handle the new AST node or enum. This typically involves modifying files in `SqlScriptDom/ScriptDom/SqlServer/ScriptGenerator/`. For the `NOT LIKE` example, this meant adding an entry to the `_booleanComparisonTypeGenerators` dictionary in `SqlScriptGeneratorVisitor.CommonPhrases.cs`.

4.  **Build the Project**:
    *   After making code changes, run a build to regenerate the parser and ensure everything compiles correctly:
        ```bash
        dotnet build
        ```

5.  **Add a Unit Test**:
    *   Create a new `.sql` file in `Test/SqlDom/TestScripts/` that contains the specific syntax for the new test case.

6.  **Define the Test Case**:
    *   Add a new `ParserTest` entry to the appropriate `Only<version>SyntaxTests.cs` files (e.g., `Only130SyntaxTests.cs`). This entry points to your new test script and defines the expected number of parsing errors for each SQL Server version.

7.  **Generate and Verify Baselines**:
    This is a critical and multi-step process:
    *   **a. Create Placeholder Baseline Files**: Before running the test, create empty or placeholder baseline files in the corresponding `Test/SqlDom/Baselines<version>/` directories. The filename must match the test script's filename.
    *   **b. Run the Test to Get the Generated Script**: Run the specific test that you just added. It is *expected to fail* because the placeholder baseline will not match the script generated by the parser.
        ```bash
        # Example filter for running a specific test
        dotnet test --filter "FullyQualifiedName~YourTestMethodName"
        ```
    *   **c. Update the Baseline Files**: Copy the "Actual" output from the test failure log. This is the correctly formatted script generated from the AST. Paste this content into all the baseline files you created in step 7a.
    *   **d. Re-run the Tests**: Run the same test command again. This time, the tests should pass, confirming that the generated script matches the new baseline.

By following these steps, you can ensure that new syntax is correctly parsed, represented in the AST, generated back into a script, and fully validated by the testing framework.
